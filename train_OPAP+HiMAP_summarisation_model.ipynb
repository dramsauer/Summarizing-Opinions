{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing results from the Multi-News paper\n",
    "\n",
    "In this notebook we will try to reproduce the results from  the [Multi-News](https://www.aclweb.org/anthology/P19-1102/) [(GitHub)](https://github.com/Alex-Fabbri/Multi-News). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They use the [OpenNMT](https://opennmt.net/) neural machine translation system, but adapted it some places.\n",
    "\n",
    "The main steps of a OpenNMT-pipeline are\n",
    "- Preprocessing \n",
    "- Model training\n",
    "- Translate\n",
    "\n",
    "You can find the documentation [here](https://opennmt.net/OpenNMT-py/quickstart.html#step-1-preprocess-the-data).\n",
    "\n",
    "\n",
    "See also the python implementation of OpenNMT [here](https://github.com/OpenNMT/OpenNMT-py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "The data consists of parallel source (src) and target (tgt) data containing one sentence per line with tokens separated by a space.\n",
    "We won't need to do preprocessing on our own, since preprocessed data is already provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code  data  output  README.md  Train_BERT_HiPMAP.ipynb\tTrain_HiPMAP.ipynb\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /opt/conda/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.5)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.4.0.44)\n",
      "Requirement already satisfied: transformers==3.1.0 in /opt/conda/lib/python3.7/site-packages (3.1.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchtext) (1.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext) (2.22.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext) (1.18.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from torchtext) (0.1.91)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext) (4.41.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (7.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from nltk) (2020.7.14)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /opt/conda/lib/python3.7/site-packages (from transformers==3.1.0) (0.8.1rc2)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3.1.0) (0.0.43)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.1.0) (3.0.12)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.1.0) (20.1)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchtext) (0.18.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (2019.11.28)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.1.0) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.1.0) (2.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext nltk opencv-python transformers==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please backup existing pt file: ../news-opinion-summarization/data/multi_news/newser_sent_500/newser_sents.train*.pt, to avoid tampering!\n"
     ]
    }
   ],
   "source": [
    "!python code/HiPMAP/preprocess.py \\\n",
    "    -train_src ../news-opinion-summarization/data/multi_news/raw/train.src.cleaned \\\n",
    "    -train_tgt ../news-opinion-summarization/data/multi_news/raw/train.tgt \\\n",
    "    -valid_src ../news-opinion-summarization/data/multi_news/raw/val.src.cleaned \\\n",
    "    -valid_tgt ../news-opinion-summarization/data/multi_news/raw/val.tgt \\\n",
    "    -save_data ../news-opinion-summarization/data/multi_news/newser_sent_500/newser_sents \\\n",
    "    -src_seq_length 10000 \\\n",
    "    -tgt_seq_length 10000 \\\n",
    "    -src_seq_length_trunc 500 \\\n",
    "    -tgt_seq_length_trunc 300 \\\n",
    "    -dynamic_dict \\\n",
    "    -share_vocab \\\n",
    "    -max_shard_size 10000000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export THC_CACHING_ALLOCATOR=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 07:37:17.940309: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-10-23 07:37:17.940366: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-10-23 07:37:17.940377: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[2020-10-23 07:37:23,943 INFO] Loading checkpoint from output/summarisation/model_newser_polarity/Okt17__step_19900.pt\n",
      "[2020-10-23 07:37:26,957 INFO] Loading vocab from checkpoint at output/summarisation/model_newser_polarity/Okt17__step_19900.pt.\n",
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "[2020-10-23 07:37:26,991 INFO]  * vocabulary size. source = 50004; target = 50004\n",
      "[2020-10-23 07:37:26,991 INFO] Building model...\n",
      "[2020-10-23 07:37:31,885 INFO] NMTModel(\n",
      "  (encoder): RNNEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(50004, 128, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (rnn): LSTM(128, 256, bidirectional=True)\n",
      "    (sent_rnn): LSTM(512, 256, bidirectional=True)\n",
      "    (bridge): ModuleList(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InputFeedRNNDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(50004, 128, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(640, 512)\n",
      "      )\n",
      "    )\n",
      "    (attn): GlobalAttention(\n",
      "      (linear_context): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
      "      (linear_out): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    )\n",
      "    (mmr_W): Linear(in_features=512, out_features=512, bias=False)\n",
      "  )\n",
      "  (generator): CopyGenerator(\n",
      "    (linear): Linear(in_features=512, out_features=50004, bias=True)\n",
      "    (linear_copy): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (softmax): Softmax(dim=1)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "[2020-10-23 07:37:31,885 INFO] encoder: 8899584\n",
      "[2020-10-23 07:37:31,885 INFO] decoder: 35728725\n",
      "[2020-10-23 07:37:31,885 INFO] * number of parameters: 44628309\n",
      "[2020-10-23 07:37:31,975 INFO] Start training...\n",
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: OrderedIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py:356: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "[2020-10-23 07:50:17,580 INFO] Step 19950/20000; acc:  28.66; ppl: 83.32; xent: 4.42; lr: 0.15000; 311/141 tok/s;    763 sec\n",
      "[2020-10-23 08:03:01,186 INFO] Step 20000/20000; acc:  30.42; ppl: 70.95; xent: 4.26; lr: 0.15000; 333/156 tok/s;   1527 sec\n",
      "[2020-10-23 08:03:08,202 WARNING] CUDA OOM was reached, cache gets emptied. Continuing with next batch...\n",
      "[2020-10-23 08:03:11,639 WARNING] CUDA OOM was reached, cache gets emptied. Continuing with next batch...\n",
      "Traceback (most recent call last):\n",
      "  File \"code/HiPMAP/train.py\", line 124, in <module>\n",
      "    main(opt)\n",
      "  File \"code/HiPMAP/train.py\", line 59, in main\n",
      "    single_main(opt, -1)\n",
      "  File \"/home/jovyan/Summarizing-Opinions/code/HiPMAP/onmt/train_single.py\", line 145, in main\n",
      "    opt.valid_steps)\n",
      "  File \"/home/jovyan/Summarizing-Opinions/code/HiPMAP/onmt/trainer.py\", line 153, in train\n",
      "    for i, batch in enumerate(train_iter):\n",
      "  File \"/home/jovyan/Summarizing-Opinions/code/HiPMAP/onmt/inputters/inputter.py\", line 466, in __iter__\n",
      "    for batch in self.cur_iter:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torchtext/data/iterator.py\", line 162, in __iter__\n",
      "    yield Batch(minibatch, self.dataset, self.device)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torchtext/data/batch.py\", line 36, in __init__\n",
      "    setattr(self, name, field.process(batch, device=device))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py\", line 234, in process\n",
      "    tensor = self.numericalize(padded, device=device)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py\", line 361, in numericalize\n",
      "    var = var.contiguous()\n",
      "RuntimeError: CUDA error: invalid resource handle\n",
      "CPU times: user 11.7 s, sys: 2 s, total: 13.7 s\n",
      "Wall time: 26min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!CUDA_VISIBLE_DEVICES=2,3,0,1 python code/HiPMAP/train.py \\\n",
    "    -save_model output/summarisation/model_newser_polarity/Okt17_ \\\n",
    "    -data ../news-opinion-summarization/data/multi_news/final_preprocessed/final \\\n",
    "    -copy_attn -accum_count 5\\\n",
    "    -global_attention mlp \\\n",
    "    -word_vec_size 128 \\\n",
    "    -rnn_size 512  -layers 1 \\\n",
    "    -encoder_type brnn \\\n",
    "    -train_steps 20000 \\\n",
    "    -max_grad_norm 4 \\\n",
    "    -dropout 0. \\\n",
    "    -batch_size 2 \\\n",
    "    -optim adagrad \\\n",
    "    -learning_rate 0.15 \\\n",
    "    -adagrad_accumulator_init 0.1 \\\n",
    "    -reuse_copy_attn \\\n",
    "    -copy_loss_by_seqlength \\\n",
    "    -bridge \\\n",
    "    -seed 777 \\\n",
    "    -world_size 1  \\\n",
    "    -gpu_ranks 0 1 2 3 \\\n",
    "    -save_checkpoint_steps 100 \\\n",
    "    -train_from output/summarisation/model_newser_polarity/Okt17__step_19900.pt\n",
    "    #-model_type fp16 \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 19 18:05:36 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 31%   44C    P8    16W / 250W |      0MiB / 11016MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 30%   42C    P8    23W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:4B:00.0 Off |                  N/A |\n",
      "| 28%   38C    P8    23W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:4C:00.0 Off |                  N/A |\n",
      "| 29%   39C    P8     2W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
